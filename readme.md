<p align="center">
  <img src="reports/figures/thumbnail.png" alt="Marketing NLP on Amazon Reviews â€” Sentiment + Topics + MLflow + Streamlit" width="900">
</p>

End-to-end sentiment + topic insights with MLflow tracking and a Streamlit mini-app.

ğŸš€ What this project does

    Cleans and prepares a public Amazon reviews dataset (category subset).

    Trains a baseline sentiment classifier (TF-IDF + Logistic Regression) with MLflow metrics/artifacts.

    Extracts themes using Topic Modeling (sklearn LDA) and saves topic labels.

    Serves a Streamlit app to analyze reviews: live sentiment + top topic(s) with human-readable names.

    Version-controlled with Git; experiments tracked with MLflow (local by default).

ğŸ“‚ Project structure

    marketing-nlp-amazon/
    â”œâ”€ app/
    â”‚  â””â”€ app.py                  # Streamlit UI
    â”œâ”€ data/
    â”‚  â”œâ”€ raw/                    # downloaded dataset (gitignored)
    â”‚  â””â”€ processed/              # cleaned CSV (gitignored)
    â”œâ”€ models/
    â”‚  â”œâ”€ baseline_tfidf_logreg.joblib
    â”‚  â””â”€ topics/                 # LDA + vectorizer artifacts
    â”œâ”€ notebooks/
    â”‚  â”œâ”€ 01_eda.ipynb
    â”‚  â””â”€ 02_introspection.ipynb
    â”œâ”€ reports/
    â”‚  â”œâ”€ figures/
    |  |  â”œâ”€ classification_report_baseline.txt
    |  |  â”œâ”€ confusion matrix_baseline.png
    â”‚  â”‚  â”œâ”€ eda_label_distribution.png
    â”‚  â”‚  â”œâ”€ eda_length_hist.png
    â”‚  â”‚  â”œâ”€ eda_top_tokens.csv
    â”‚  â”‚  â”œâ”€ eda_top_tokens.png
    â”‚  â”‚  â”œâ”€ model_top_positive_ngrams.csv
    â”‚  â”‚  â”œâ”€ model_top_pos_bars.png
    â”‚  â”‚  â”œâ”€ model_top_negative_ngrams.csv
    â”‚  â”‚  â”œâ”€ model_top_neg_bars.png
    â”‚  â”‚  â””â”€ topics/
    â”‚  â”‚     â””â”€ topic_0_top_terms.png ... topic_k_top_terms.png
    â”‚  â””â”€ topics/
    â”‚     â”œâ”€ lda_top_terms.csv
    â”‚     â”œâ”€ lda_doc_topics.csv
    â”‚     â””â”€ lda_topic_labels.csv
    â”œâ”€ src/
    â”‚  â”œâ”€ data.py                 # load + clean
    â”‚  â”œâ”€ train_baseline.py       # TFIDF + LR + MLflow
    â”‚  â””â”€ topics.py               # LDA + MLflow + labels
    â”œâ”€ .gitignore
    â”œâ”€ requirements.txt
    â””â”€ README.md

ğŸ§° Setup

    Python: 3.11 recommended (for best package compatibility)
    OS: Windows (PowerShell commands shown); bash equivalents included

    1) Create & activate a virtual env
        
        python -m venv .venv
        .\.venv\Scripts\Activate.ps1

    2) Install dependencies
        pip install -r requirements.txt
        python -m nltk.downloader punkt stopwords
    
ğŸ“¦ Data
    Download a small Amazon Reviews category file [Musical_Instruments_5.json.gz](https://mcauleylab.ucsd.edu/public_datasets/data/amazon_v2/categoryFilesSmall/Musical_Instruments_5.json.gz) and place it in
        
          data/raw/Musical_Instruments_5.json.gz

    The link for Amazon rviews daatset [Amazon reviews](https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/)

â–¶ï¸ How to run
    
    A) Prepare data (cleaning + labeling)
        python src/data.py
        # output: data/processed/amazon_mi_clean.csv

    B) Train baseline sentiment (TF-IDF + Logistic Regression) with MLflow logging
        python src/train_baseline.py --data data/processed/amazon_mi_clean.csv
        # outputs:
        # - models/baseline_tfidf_logreg.joblib
        # - reports/figures/confusion matrix_baseline.png
        # - reports/figures/classification_report_baseline.txt
        # - MLflow run with metrics + artifacts

    C) Topic modeling (sklearn LDA) + labels + artifacts
        python src/topics.py --data data/processed/amazon_mi_clean.csv --n_topics 10
        # outputs:
        # - models/topics/{count_vectorizer.joblib, lda_model.joblib}
        # - reports/topics/{lda_top_terms.csv, lda_doc_topics.csv, lda_topic_labels.csv}
        # - reports/figures/topics/topic_*.png
        # - MLflow run with metrics (perplexity, topic_diversity) + artifacts
    
    d) Launch the Streamlit app
        streamlit run app/app.py
            Paste any review text and click Analyze to see:
            Sentiment (+ confidence)
            Likely topics (with human-readable names from lda_topic_labels.csv)
            Top terms for the predicted topics
            
ğŸ“Š MLflow (experiments & artifacts)
Start the UI locally:
    mlflow ui
    Open the printed URL (usually http://127.0.0.1:5000) to view:

    Metrics: val_accuracy, val_precision, val_recall, val_f1, val_auc

    Artifacts: confusion matrix image, classification report, topic CSVs & plots

    Model artifacts logged under model/

    Tip: To track remotely on Azure ML later, set the MLflow tracking URI to your Azure ML workspace; the code already uses standard MLflow APIs.

ğŸ–¼ï¸ Screenshots

**EDA â€” Label distribution**  

![Label Distribution](reports/figures/eda_label_distribution.png)

**EDA â€” Review length**  

![Review Length](reports/figures/eda_length_hist.png)

**Model introspection â€” Top positive n-grams**  

![Top Positive N-grams](reports/figures/model_top_pos_bars.png)

**Model introspection â€” Top negative n-grams**  

![Top Negative N-grams](reports/figures/model_top_neg_bars.png)

**Topics â€” Example top terms**  

![Topic 0 Top Terms](reports/figures/topics/topic_1_top_terms.png)

**Streamlit app**  

![Streamlit App](reports/figures/streamlit_app.png)

**MLflow run**  

![MLflow Run](reports/figures/mlflow_run.png)

âœ… Example baseline results

    | Metric    | Value |
    | --------- | ----- |
    | Accuracy  | 0.867 |
    | Precision | 0.934 |
    | Recall    | 0.879 |
    | F1-Score  | 0.906 |
    | AUC       | 0.932 |

ğŸ§­ Roadmap

    Hyperparameter search (C, class weights, n-gram ranges)

    Swap TF-IDF â†’ small transformer (e.g., sentence-transformers)

    Better topic labeling (manual curation in lda_topic_labels.csv)

    Azure ML remote tracking + deployment (Project 2)

    Batch scoring API (FastAPI) for reviews

ğŸ”’ License
This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.
